{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da808e1c",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34326a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import unicodedata\n",
    "import os\n",
    "import yfinance as yf\n",
    "import math\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import nltk\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from matplotlib.dates import DateFormatter\n",
    "import statistics\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.preprocessing import LabelEncoder,label_binarize\n",
    "from textblob import TextBlob, Word\n",
    "from datetime import datetime, timedelta\n",
    "import time\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, roc_curve, auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9988c59b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('vader_lexicon')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ae62135-8274-4d0a-8847-ac46d961e71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "work_directory = os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba4411d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_tweet_path=work_directory+\"/stock_tweets.csv\"\n",
    "stock_data_path=work_directory+\"/stock_yfinance_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd79f7e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = ['TSLA' ,'SMCI', 'AMZN', 'AVGO' ,'ALB' ,'MSFT' ,'META', 'NFLX' ,'NVDA']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06abf98",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "import pandas as pd\n",
    "import time\n",
    "\n",
    "# Setup Selenium WebDriver\n",
    "service = Service(ChromeDriverManager().install())\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument(\"--headless\")  # Enable headless mode\n",
    "chrome_options.add_argument(\"--no-sandbox\")\n",
    "chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "driver = webdriver.Chrome(service=service, options=chrome_options)\n",
    "\n",
    "\n",
    "def last_11_months(time_text):\n",
    "    if 'months' in time_text:\n",
    "        months = int(time_text.split()[0])\n",
    "        return months <= 11\n",
    "    return True\n",
    "\n",
    "# Initialize an empty DataFrame to collect all news\n",
    "head1 = pd.DataFrame()\n",
    "\n",
    "for ticker in tickers:\n",
    "    url = f'https://finance.yahoo.com/quote/{ticker}/news/'\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    print(f'Collecting news related to {ticker}')\n",
    "    previous_height = driver.execute_script('return document.body.scrollHeight')\n",
    "    count = 0\n",
    "    news = []\n",
    "    \n",
    "    while True:\n",
    "        content_divs = driver.find_elements(By.CSS_SELECTOR, 'div.content.svelte-w27v8j')\n",
    "        \n",
    "        latest_time_text = ''\n",
    "        for content_div in content_divs:\n",
    "            try:\n",
    "                a_tag = content_div.find_element(By.CSS_SELECTOR, 'a.subtle-link.fin-size-small.titles.noUnderline.svelte-wdkn18')\n",
    "                title = a_tag.get_attribute('title') if a_tag else None\n",
    "                \n",
    "                publishing_div = content_div.find_element(By.CSS_SELECTOR, 'div.publishing.font-condensed.svelte-1k3af9g')\n",
    "                time_text = publishing_div.text.split('â€¢')[-1].strip() if publishing_div else None\n",
    "                latest_time_text = time_text\n",
    "                if latest_time_text and last_12_months(latest_time_text):\n",
    "                    news.append({'Date': time_text, 'Headline': title, 'Stock Name': ticker})\n",
    "            except Exception as e:\n",
    "                print(f\"Error extracting data: {e}\")\n",
    "\n",
    "        driver.execute_script('window.scrollTo(0, document.body.scrollHeight)')\n",
    "        time.sleep(4)\n",
    "        new_height = driver.execute_script('return document.body.scrollHeight')\n",
    "        \n",
    "        if new_height == previous_height:\n",
    "            count += 1\n",
    "            if count > 4:\n",
    "                break\n",
    "        else:\n",
    "            previous_height = new_height\n",
    "            count = 0\n",
    "        \n",
    "        if latest_time_text and not last_11_months(latest_time_text):\n",
    "            break\n",
    "    \n",
    "    df_news = pd.DataFrame(news)\n",
    "    \n",
    "    if not df_news.empty:\n",
    "        print(f'Starting news related to {ticker} is {df_news[\"Date\"].iloc[0]}')\n",
    "        print(f'Ending news related to {ticker} is {df_news[\"Date\"].iloc[-1]}')\n",
    "        print('Dataset size is ', df_news.shape[0])\n",
    "        head1 = pd.concat([head1, df_news], ignore_index=True)\n",
    "\n",
    "# Close the WebDriver\n",
    "driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ef8bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert relative time text to actual date\n",
    "def convert_to_date(time_text):\n",
    "    now = datetime.now()\n",
    "    if time_text == 'yesterday':\n",
    "        return now - timedelta(days=1)\n",
    "    if time_text == 'last month':\n",
    "        return now - timedelta(days=30)\n",
    "    if 'minute' in time_text:\n",
    "        minutes = int(time_text.split()[0])\n",
    "        return now - timedelta(minutes=minutes)\n",
    "    elif 'hour' in time_text:\n",
    "        hours = int(time_text.split()[0])\n",
    "        return now - timedelta(hours=hours)\n",
    "    elif 'day' in time_text:\n",
    "        days = int(time_text.split()[0])\n",
    "        return now - timedelta(days=days)\n",
    "    elif 'week' in time_text:\n",
    "        weeks = int(time_text.split()[0])\n",
    "        return now - timedelta(weeks=weeks)\n",
    "    elif 'month' in time_text:\n",
    "        months = int(time_text.split()[0])\n",
    "        return now - timedelta(days=30*months)\n",
    "    elif 'today' in time_text.lower():\n",
    "        return now\n",
    "    else:\n",
    "        return None\n",
    "head1['Date'] = head1['Date'].apply(convert_to_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b6bf08-5879-4545-bc52-585ebaa1cf5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "\n",
    "def fetch_news(year, month, api_key):\n",
    "    url = f\"https://api.nytimes.com/svc/archive/v1/{year}/{month}.json?api-key={api_key}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        articles = data['response']['docs']\n",
    "        return articles\n",
    "    else:\n",
    "        print(f\"Failed to fetch data for {year}-{month}: {response.status_code}\")\n",
    "        return []\n",
    "\n",
    "# Initialize lists for headlines and dates\n",
    "all_headlines = []\n",
    "all_dates = []\n",
    "\n",
    "# API key\n",
    "api_key = 'Z7LiuLGnozS868StkM3QcbQhsJA8acDt'\n",
    "\n",
    "# Fetch data for each year from 2010 to 2024\n",
    "for year in range(2020, 2024):\n",
    "    for month in range(1, 13):\n",
    "        print(f\"Fetching data for {year}-{month}\")\n",
    "        try:\n",
    "            articles = fetch_news(year, month, api_key)\n",
    "            if articles:\n",
    "                all_headlines.extend([article['headline']['main'] for article in articles])\n",
    "                all_dates.extend([article['pub_date'] for article in articles])\n",
    "            # Sleep to respect API rate limits\n",
    "            time.sleep(6)  # Adjust sleep time as needed based on API rate limits\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {year}-{month}: {e}\")\n",
    "\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aecad791",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame\n",
    "df = pd.DataFrame({'Date': all_dates, 'Headline': all_headlines})\n",
    "\n",
    "# Convert datetime column to datetime format\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df['Stock Name']='NVDA'\n",
    "print('data extracted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9635f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1 = pd.concat([head1, df], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ac14cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the collected news to a CSV file\n",
    "head1.to_csv(stock_tweet_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8970e709",
   "metadata": {},
   "source": [
    "## Related stock data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e98b29e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock=pd.DataFrame()  # Example ticker symbol for Apple\n",
    "start_date = \"2023-07-01\"  # Specify start date\n",
    "end_date = \"2024-06-14\"   \n",
    "dfs = [] \n",
    "for ticker in tickers:\n",
    "    data = yf.download(ticker, start=start_date, end=end_date).reset_index()  # Reset index to make 'Date' a column\n",
    "    data['Stock Name'] = ticker  # Add a column for the ticker symbol\n",
    "    dfs.append(data)\n",
    "data=yf.download('NVDA',start='2020-01-01',end='2023-12-30').reset_index()\n",
    "data['Stock Name']='NVDA'\n",
    "dfs.append(data)\n",
    "# Combine all individual dataframes into a single dataframe\n",
    "Stock = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "# Reorder columns as per the desired format\n",
    "Stock = Stock[['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume', 'Stock Name']]\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "352d7073",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03002f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ca9c750",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46d2d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock.to_csv(stock_data_path, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a799b6da",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11002920",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1=pd.read_csv(stock_tweet_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a98845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(head1['Stock Name'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430b8d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e8d5bd",
   "metadata": {},
   "source": [
    "## Sentiment analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "236c141b",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1['polarity_score']=''\n",
    "head1['Headline'] = head1['Headline'].astype(str)\n",
    "head1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3ad3ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_analyze = SentimentIntensityAnalyzer()\n",
    "\n",
    "# Analyze each tweet and store the compound score\n",
    "for ind, row in head1.iterrows():\n",
    "    headline = row[\"Headline\"]\n",
    "    sentence_i = unicodedata.normalize(\"NFKD\", headline)\n",
    "    sent_sent = sent_analyze.polarity_scores(sentence_i)\n",
    "    head1.at[ind, \"polarity_score\"] = sent_sent[\"compound\"]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2c169",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf98f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1[\"sentiment_label\"] = head1[\"Headline\"].apply(lambda x: \"pos\" if sent_analyze.polarity_scores(x)[\"compound\"] > 0 else (\"neu\" if sent_analyze.polarity_scores(x)[\"compound\"] ==0 else \"neg\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd60aa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc12b2b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea50900a",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1[\"sentiment_label\"] = LabelEncoder().fit_transform(head1[\"sentiment_label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "670077b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1['Date'] = pd.to_datetime(head1['Date'], errors='coerce', utc=True)\n",
    "head1[\"Date\"] = head1[\"Date\"].dt.date\n",
    "head1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68063703",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1[\"sentiment_label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad369b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "head1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4773fd59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing function\n",
    "def preprocessing(df):\n",
    "    # Convert to lower case\n",
    "    df = df.str.lower()\n",
    "    # Remove punctuation\n",
    "    df = df.str.replace('[^\\w\\s]', '', regex=True)\n",
    "    # Remove numbers\n",
    "    df = df.str.replace('\\d', '', regex=True)\n",
    "    # Remove stopwords\n",
    "    sw = stopwords.words('english')\n",
    "    df = df.apply(lambda x: \" \".join(x for x in str(x).split() if x not in sw))\n",
    "    # Remove infrequent words\n",
    "    temp_df = pd.Series(' '.join(df).split()).value_counts()\n",
    "    drops = temp_df[temp_df <= 1]\n",
    "    df = df.apply(lambda x: \" \".join(x for x in x.split() if x not in drops))\n",
    "    return df\n",
    "\n",
    "# Tokenization function\n",
    "def tokenization(df):\n",
    "    df = df.apply(lambda x: TextBlob(x).words)\n",
    "    return df\n",
    "\n",
    "# Lemmatization function\n",
    "def lemmatized(df):\n",
    "    df = df.apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))\n",
    "    return df\n",
    "\n",
    "# Term frequency function\n",
    "def term_fre(df):\n",
    "    tf = df.apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()\n",
    "    tf.columns = ['words', 'tf']\n",
    "    tf_sorted = tf.sort_values(by='tf', ascending=False)\n",
    "    return tf_sorted\n",
    "\n",
    "# TF-IDF function\n",
    "def tfidf(X, fit_vectorizer=None):\n",
    "    if fit_vectorizer is None:\n",
    "        fit_vectorizer = TfidfVectorizer()\n",
    "        X_tf_idf_word = fit_vectorizer.fit_transform(X)\n",
    "    else:\n",
    "        X_tf_idf_word = fit_vectorizer.transform(X)\n",
    "    return X_tf_idf_word, fit_vectorizer\n",
    "\n",
    "# Function to preprocess and vectorize\n",
    "def givefinalX(X, vectorizer=None):\n",
    "    # Apply preprocessing\n",
    "    X = preprocessing(X)\n",
    "\n",
    "    # Apply tokenization (if needed)\n",
    "    # X = tokenization(X)\n",
    "\n",
    "    # Apply lemmatization\n",
    "    X = lemmatized(X)\n",
    "\n",
    "    # Convert to TF-IDF\n",
    "    X_tf_idf_word, vectorizer = tfidf(X, vectorizer)\n",
    "    return X_tf_idf_word, vectorizer\n",
    "\n",
    "\n",
    "# Split the data\n",
    "X = head1['Headline']\n",
    "y = head1['sentiment_label']\n",
    "# Split into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a58d67",
   "metadata": {},
   "source": [
    "## Sentiment modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a01f0b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to TF-IDF\n",
    "X_tf_idf_word_train, vectorizer = givefinalX(X_train)\n",
    "\n",
    "X_tf_idf_word_test, _ = givefinalX(X_test, vectorizer)\n",
    "\n",
    "# Train RandomForestClassifier\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_tf_idf_word_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b386f9",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Cross-validation score\n",
    "cv_score = cross_val_score(rf_model, X_tf_idf_word_train, y_train, cv=5, n_jobs=-1).mean()\n",
    "print(f\"Cross-validation score: {cv_score}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82885e52",
   "metadata": {},
   "outputs": [],
   "source": [
    " # Predictions on test set\n",
    "y_pred = rf_model.predict(X_tf_idf_word_test)\n",
    "y_prob = rf_model.predict_proba(X_tf_idf_word_test)\n",
    "print(f\"Test set predictions: {y_pred}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6de327b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "roc_auc = roc_auc_score(label_binarize(y_test, classes=[0, 1, 2]), y_prob, average='macro', multi_class='ovr')\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(f'Accuracy: {accuracy}')\n",
    "print(f'Precision: {precision}')\n",
    "print(f'Recall: {recall}')\n",
    "print(f'F1-Score: {f1}')\n",
    "print(f'ROC AUC: {roc_auc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53977a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ROC Curve for each class\n",
    "fpr = {}\n",
    "tpr = {}\n",
    "roc_auc = {}\n",
    "\n",
    "# Binarize the output\n",
    "y_test_bin = label_binarize(y_test, classes=[0, 1, 2])\n",
    "n_classes = y_test_bin.shape[1]\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test_bin[:, i], y_prob[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "# Plot ROC curve for each class\n",
    "plt.figure()\n",
    "colors = ['blue', 'red', 'green']\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='ROC curve of class {0} (area = {1:0.2f})'\n",
    "             ''.format(i, roc_auc[i]))\n",
    "\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic for Multi-Class')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff68e5ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the test set\n",
    "test_score = rf_model.score(X_tf_idf_word_test, y_test)\n",
    "print(f\"Test set score: {test_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1bc511",
   "metadata": {},
   "source": [
    "## Stock prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61523e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = head1[[\"Date\",\"polarity_score\",\"Stock Name\"]]\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78392fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f9a795d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"Stock Name\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cabc616a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by \"Date\" and \"Stock Name\" and calculate the mean of \"sentence_score\"\n",
    "df_grouped = df.groupby([\"Date\", \"Stock Name\"]).mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c95c6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_grouped.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bda399c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1672ed70",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534b53a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_grouped.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ade01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock=pd.read_csv(stock_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e29548",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(Stock.shape)\n",
    "Stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a05d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock['Stock Name'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa51b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock['Stock Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b087ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "Stock[\"Date\"]=pd.to_datetime(Stock[\"Date\"])\n",
    "Stock[\"Date\"]=Stock[\"Date\"].dt.date\n",
    "print(Stock.shape)\n",
    "Stock.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43fa6753",
   "metadata": {},
   "source": [
    "## Let's See affect of tweet on a specific stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634e3640",
   "metadata": {},
   "outputs": [],
   "source": [
    "stk_name='NVDA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32e68f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock = Stock[Stock[\"Stock Name\"] == stk_name]\n",
    "stock[\"Date\"] = pd.to_datetime(stock[\"Date\"])\n",
    "stock[\"Date\"] = stock[\"Date\"].dt.date\n",
    "# Reset the index of appl_stock\n",
    "stock.reset_index(drop=True, inplace=True)\n",
    "stock.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a26b99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "stock.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbe25e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now filter the grouped DataFrame for rows\n",
    "df = df_grouped[df_grouped['Stock Name'] == stk_name]\n",
    "# Reset the index of appl_df\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016c8191",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e9a6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now perform the join operation\n",
    "df = stock.join(df.set_index([\"Date\", \"Stock Name\"]), on=[\"Date\", \"Stock Name\"], how=\"inner\")\n",
    "df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feaec38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e9e01d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91c3a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(df[\"Date\"], df[\"Adj Close\"])\n",
    "ax.set(xlabel=\"Date\",ylabel=\"USD\",title=f\"{stk_name} Stock Price\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86635c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(df[\"Date\"], df[\"polarity_score\"])\n",
    "ax.set(xlabel=\"Date\",ylabel=\"polarity Score\",title=f\"{stk_name}'s Public Sentiment\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7ac398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fin_df = appl_df[[\"Date\",\"Close\",\"sentence_score\"]]\n",
    "fin_df=df\n",
    "# fin_df = fin_df.reset_index(drop=True)\n",
    "print(fin_df.shape)\n",
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d6bc6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SentimentAdjustedMA(df, ma_days):\n",
    "    def weight_multiplier(close,sent_score):\n",
    "        maxi = max(close)\n",
    "        mini = min(close)\n",
    "        len_close = len(close)\n",
    "        if len_close<2:\n",
    "            interval = math.sqrt(close[0])\n",
    "        else:\n",
    "            interval = statistics.variance(close)\n",
    "        max_var = interval\n",
    "        weighted=0\n",
    "        for i in range(len_close):\n",
    "            if sent_score[i] < 0:\n",
    "                weighted += close[i] + (2*sent_score[i]*max_var)\n",
    "            else:\n",
    "                weighted += close[i] + (sent_score[i]*max_var)\n",
    "        return weighted/len_close-1\n",
    "    samas = [df.loc[0,\"Adj Close\"]]\n",
    "    rows = df.shape[0]\n",
    "    for i in range(1,rows):\n",
    "        if i < ma_days:\n",
    "            mini_df = df.iloc[:i+1,:]\n",
    "        elif i + ma_days >= rows:\n",
    "            mini_df = df.iloc[i:,:]\n",
    "        else:\n",
    "            mini_df = df.iloc[i-ma_days+1:i+1,:]\n",
    "        sama_value = weight_multiplier(mini_df[\"Adj Close\"].tolist(),mini_df[\"polarity_score\"].tolist())\n",
    "        samas.append(sama_value)\n",
    "    return samas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b58632",
   "metadata": {},
   "outputs": [],
   "source": [
    "sma5= SentimentAdjustedMA(fin_df, ma_days=5)\n",
    "fin_df[\"SMA(5)\"] = sma5\n",
    "sma20= SentimentAdjustedMA(fin_df, ma_days=10)\n",
    "fin_df[\"SMA(20)\"] = sma20\n",
    "fin_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac9d0528",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(15,8))\n",
    "ax.plot(fin_df[\"Date\"], fin_df[\"SMA(5)\"], label=\"SMA(5)\", linestyle=\"--\", color=\"g\")\n",
    "ax.plot(fin_df[\"Date\"], fin_df[\"Adj Close\"], label=\"Original\", color=\"b\")\n",
    "ax.set(xlabel=\"Date\",ylabel=\"USD\",title=f\"{stk_name} Stock Price\")\n",
    "ax.xaxis.set_major_formatter(DateFormatter(\"%Y\"))\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d66d13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the dataframe by the 'Date' column\n",
    "fin_df = fin_df.sort_values(by='Date')\n",
    "\n",
    "# Reset the index to keep the dataframe tidy\n",
    "fin_df = fin_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a681b063",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate signals based on polarity score and additional filter (SMA)\n",
    "def generate_signals(df):\n",
    "    df['SMA'] = df['Close'].rolling(window=20).mean()  # 20-day simple moving average\n",
    "    df['Signal'] = 0\n",
    "    df['Signal'] = np.where((df['polarity_score'] > 0) & (df['Close'] > df['SMA']), 1, df['Signal'])\n",
    "    df['Signal'] = np.where((df['polarity_score'] < 0) & (df['Close'] < df['SMA']), -1, df['Signal'])\n",
    "    df['Order'] = df['Signal'].diff()\n",
    "    return df\n",
    "\n",
    "# Calculate returns and performance metrics with stop-loss, take-profit, and position sizing\n",
    "def calculate_performance(df, initial_cash=1000, stop_loss_pct=0.10, take_profit_pct=0.20, position_size_pct=0.20):\n",
    "    cash = initial_cash\n",
    "    position = 0\n",
    "    purchase_price = 0\n",
    "    portfolio_values = []\n",
    "    \n",
    "    for index, row in df.iterrows():\n",
    "        if row['Order'] == -1 and cash > 0:  # Buy signal\n",
    "            position = (cash * position_size_pct) / row['Close']\n",
    "            cash += position * row['Close']\n",
    "            purchase_price = row['Close']\n",
    "        elif row['Order'] == 1 and position > 0:  # Sell signal\n",
    "            cash -= position * row['Close']\n",
    "            position = 0\n",
    "        elif position > 0:\n",
    "            if row['Close'] < purchase_price * (1 - stop_loss_pct):  # Stop-loss condition\n",
    "                cash += position * row['Close']\n",
    "                position = 0\n",
    "                df.loc[index, 'Order'] = -1  # Mark this as a sell due to stop-loss\n",
    "            elif row['Close'] > purchase_price * (1 + take_profit_pct):  # Take-profit condition\n",
    "                cash += position * row['Close']\n",
    "                position = 0\n",
    "                df.loc[index, 'Order'] = -1  # Mark this as a sell due to take-profit\n",
    "\n",
    "        portfolio_value = cash + position * row['Close']\n",
    "        portfolio_values.append(portfolio_value)\n",
    "\n",
    "    df['Portfolio Value'] = portfolio_values\n",
    "    final_portfolio_value = portfolio_values[-1]\n",
    "    returns = df['Portfolio Value'].pct_change().dropna()\n",
    "    sharpe_ratio = (252**0.5) * returns.mean() / returns.std()  # Assuming 252 trading days in a year\n",
    "    total_trades = len(df[df['Order'].abs() == 1])\n",
    "    winning_trades = len(df[(df['Order'] == -1) & (df['Close'] > df['Close'].shift(1))])\n",
    "    win_ratio = winning_trades / total_trades if total_trades > 0 else 0\n",
    "\n",
    "    performance = {\n",
    "        \"Final Portfolio Value\": final_portfolio_value,\n",
    "        \"Sharpe Ratio\": sharpe_ratio,\n",
    "        \"Number of Trades Executed\": total_trades,\n",
    "        \"Win Ratio\": win_ratio\n",
    "    }\n",
    "\n",
    "    return performance\n",
    "\n",
    "# Load your dataframe\n",
    "# Ensure that the 'Date' column is in datetime format and sort by date\n",
    "fin_df['Date'] = pd.to_datetime(fin_df['Date'])\n",
    "fin_df = fin_df.sort_values(by='Date')\n",
    "\n",
    "# Generate signals and calculate performance\n",
    "fin_df = generate_signals(fin_df)\n",
    "performance = calculate_performance(fin_df)\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Final Portfolio Value: ${performance['Final Portfolio Value']:.2f}\")\n",
    "print(f\"Sharpe Ratio: {performance['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Number of Trades Executed: {performance['Number of Trades Executed']}\")\n",
    "print(f\"Win Ratio: {performance['Win Ratio']:.2f}\")\n",
    "\n",
    "# Plotting\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fin_df['Date'], fin_df['Close'], label='Closing Price')\n",
    "\n",
    "# Plot buy signals\n",
    "buy_signals = fin_df[fin_df['Order'] == 1]\n",
    "plt.plot(buy_signals['Date'], buy_signals['Close'], '^', markersize=10, color='g', label='Buy Signal')\n",
    "\n",
    "# Plot sell signals\n",
    "sell_signals = fin_df[fin_df['Order'] == -1]\n",
    "plt.plot(sell_signals['Date'], sell_signals['Close'], 'v', markersize=10, color='r', label='Sell Signal')\n",
    "\n",
    "plt.title('Closing Price and Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Plot portfolio value\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(fin_df['Date'], fin_df['Portfolio Value'], label='Portfolio Value')\n",
    "plt.title('Portfolio Value Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "final_path=work_directory+\"/signals.csv\"\n",
    "fin_df.to_csv('final_path', index=False)  # Adjust the path to your desired output file location\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e0a550",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot buy signals\n",
    "buy_signals = fin_df[fin_df['Order'] == 1]\n",
    "plt.scatter(buy_signals['Date'], buy_signals['Close'], marker='^', color='green', label='Buy Signal', alpha=1)\n",
    "\n",
    "# Plot sell signals\n",
    "sell_signals = fin_df[fin_df['Order'] == -1]\n",
    "plt.scatter(sell_signals['Date'], sell_signals['Close'], marker='v', color='red', label='Sell Signal', alpha=1)\n",
    "\n",
    "plt.title('Closing Price and Buy/Sell Signals')\n",
    "plt.xlabel('Date')\n",
    "\n",
    "\n",
    "plt.ylabel('Price')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58bb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the Portfolio Value over Time\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.plot(fin_df['Date'], fin_df['Portfolio Value'], label='Portfolio Value', color='purple')\n",
    "plt.title('Portfolio Value Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Portfolio Value')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Print performance metrics\n",
    "print(f\"Final Portfolio Value: ${performance['Final Portfolio Value']:.2f}\")\n",
    "print(f\"Sharpe Ratio: {performance['Sharpe Ratio']:.2f}\")\n",
    "print(f\"Number of Trades Executed: {performance['Number of Trades Executed']}\")\n",
    "print(f\"Win Ratio: {performance['Win Ratio']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa35a0ab-6418-4c5a-a8b6-134ffbe105d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb51fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4284305",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2c4beb1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea822533",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8083c8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb582d18",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0e949",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e84fd3e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcdc1e7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6783942a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b290c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9703f69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1301add7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e71f02b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9261198d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a53005",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aefafa7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5f848",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36368eda",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
